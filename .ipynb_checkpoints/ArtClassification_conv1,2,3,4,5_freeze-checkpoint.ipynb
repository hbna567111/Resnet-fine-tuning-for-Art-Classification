{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708d6685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>phash</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_acolman-1...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>acolman-1-1955</td>\n",
       "      <td>bebbeb018a7d80a8</td>\n",
       "      <td>1922</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_chicago-6...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>chicago-6-1961</td>\n",
       "      <td>d7d0781be51fc00e</td>\n",
       "      <td>1382</td>\n",
       "      <td>1746</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_glouceste...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>gloucester-16a-1944</td>\n",
       "      <td>9f846e5a6c639325</td>\n",
       "      <td>1382</td>\n",
       "      <td>1857</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_jerome-ar...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>jerome-arizona-1949</td>\n",
       "      <td>a5d691f85ac5e4d0</td>\n",
       "      <td>1382</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_kentucky-...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>kentucky-4-1951</td>\n",
       "      <td>880df359e6b11db1</td>\n",
       "      <td>1382</td>\n",
       "      <td>1625</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename         artist  \\\n",
       "0  Abstract_Expressionism/aaron-siskind_acolman-1...  aaron siskind   \n",
       "1  Abstract_Expressionism/aaron-siskind_chicago-6...  aaron siskind   \n",
       "2  Abstract_Expressionism/aaron-siskind_glouceste...  aaron siskind   \n",
       "3  Abstract_Expressionism/aaron-siskind_jerome-ar...  aaron siskind   \n",
       "4  Abstract_Expressionism/aaron-siskind_kentucky-...  aaron siskind   \n",
       "\n",
       "                        genre          description             phash  width  \\\n",
       "0  ['Abstract Expressionism']       acolman-1-1955  bebbeb018a7d80a8   1922   \n",
       "1  ['Abstract Expressionism']       chicago-6-1961  d7d0781be51fc00e   1382   \n",
       "2  ['Abstract Expressionism']  gloucester-16a-1944  9f846e5a6c639325   1382   \n",
       "3  ['Abstract Expressionism']  jerome-arizona-1949  a5d691f85ac5e4d0   1382   \n",
       "4  ['Abstract Expressionism']      kentucky-4-1951  880df359e6b11db1   1382   \n",
       "\n",
       "   height  genre_count subset  \n",
       "0    1382            1  train  \n",
       "1    1746            1  train  \n",
       "2    1857            1  train  \n",
       "3    1849            1  train  \n",
       "4    1625            1  train  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_classes = pd.read_csv('./archive/classes.csv')\n",
    "df_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99cfbde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119\n"
     ]
    }
   ],
   "source": [
    "print(len(df_classes.groupby([\"artist\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb60f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsoyeon/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subset</th>\n",
       "      <th>artist</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>uncertain artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>vincent van gogh</td>\n",
       "      <td>378</td>\n",
       "      <td>1510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>nicholas roerich</td>\n",
       "      <td>363</td>\n",
       "      <td>1453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>pierre auguste renoir</td>\n",
       "      <td>280</td>\n",
       "      <td>1117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>claude monet</td>\n",
       "      <td>267</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>pyotr konchalovsky</td>\n",
       "      <td>185</td>\n",
       "      <td>739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>camille pissarro</td>\n",
       "      <td>177</td>\n",
       "      <td>707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>albrecht durer</td>\n",
       "      <td>166</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>john singer sargent</td>\n",
       "      <td>157</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>rembrandt</td>\n",
       "      <td>155</td>\n",
       "      <td>621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>marc chagall</td>\n",
       "      <td>153</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>pablo picasso</td>\n",
       "      <td>153</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>gustave dore</td>\n",
       "      <td>151</td>\n",
       "      <td>602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>boris kustodiev</td>\n",
       "      <td>127</td>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>edgar degas</td>\n",
       "      <td>122</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>paul cezanne</td>\n",
       "      <td>116</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ivan aivazovsky</td>\n",
       "      <td>116</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>martiros saryan</td>\n",
       "      <td>115</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>eugene boudin</td>\n",
       "      <td>111</td>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>childe hassam</td>\n",
       "      <td>110</td>\n",
       "      <td>437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>ilya repin</td>\n",
       "      <td>108</td>\n",
       "      <td>431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>ivan shishkin</td>\n",
       "      <td>104</td>\n",
       "      <td>416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>raphael kirchner</td>\n",
       "      <td>103</td>\n",
       "      <td>413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>henri matisse</td>\n",
       "      <td>98</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>salvador dali</td>\n",
       "      <td>96</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>camille corot</td>\n",
       "      <td>96</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subset                 artist  test  train  uncertain artist\n",
       "1074         vincent van gogh   378   1510                 0\n",
       "809          nicholas roerich   363   1453                 0\n",
       "898     pierre auguste renoir   280   1117                 2\n",
       "190              claude monet   267   1067                 0\n",
       "917        pyotr konchalovsky   185    739                 0\n",
       "158          camille pissarro   177    707                 0\n",
       "34             albrecht durer   166    662                 0\n",
       "599       john singer sargent   157    625                 1\n",
       "932                 rembrandt   155    621                 0\n",
       "719              marc chagall   153    612                 0\n",
       "846             pablo picasso   153    610                 0\n",
       "420              gustave dore   151    602                 0\n",
       "148           boris kustodiev   127    506                 0\n",
       "252               edgar degas   122    487                 2\n",
       "859              paul cezanne   116    463                 0\n",
       "495           ivan aivazovsky   116    461                 0\n",
       "749           martiros saryan   115    461                 0\n",
       "289             eugene boudin   111    444                 0\n",
       "180             childe hassam   110    437                 0\n",
       "476                ilya repin   108    431                 0\n",
       "504             ivan shishkin   104    416                 0\n",
       "929          raphael kirchner   103    413                 0\n",
       "448             henri matisse    98    393                 0\n",
       "978             salvador dali    96    385                 0\n",
       "157             camille corot    96    381                 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:10722, valid:5281, test:4007\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "N_TOP = 25\n",
    "\n",
    "df = df_classes.groupby([\"subset\",\"artist\"]).size().reset_index()\n",
    "df.columns = [\"subset\", \"artist\", \"size\"]\n",
    "df = df.pivot(index=\"artist\",columns=\"subset\", values=\"size\")\n",
    "df = df.reset_index()\n",
    "df = df.fillna(0).sort_values(by=\"train\", ascending=False)\n",
    "df[\"train\"] = df[\"train\"].astype(np.int16)\n",
    "df[\"test\"] = df[\"test\"].astype(np.int16)\n",
    "df[\"uncertain artist\"] = df[\"uncertain artist\"].astype(np.int16)\n",
    "\n",
    "df=df.sort_values(by=\"train\", ascending=False)\n",
    "\n",
    "top_artists = df[\"artist\"].values[:N_TOP]\n",
    "display(df.head(N_TOP))\n",
    "\n",
    "df_all = df_classes[df_classes[\"artist\"].isin(top_artists)].reset_index(drop = True)\n",
    "le = LabelEncoder()\n",
    "df_all[\"artist_class\"] = le.fit_transform(df_all[\"artist\"].values)\n",
    "class_names = le.classes_\n",
    "\n",
    "    \n",
    "    \n",
    "df_train = df_all.query(\"subset == 'train'\").reset_index(drop = True)\n",
    "df_test = df_all.query(\"subset == 'test'\").reset_index(drop = True)\n",
    "\n",
    "\n",
    "df_train, df_valid, y_train, y_valid =  train_test_split(df_train, df_train[\"artist\"], \n",
    "                                                                   test_size=0.33, random_state=42, \n",
    "                                                                   stratify=df_train[\"artist\"])\n",
    "\n",
    "\n",
    "print(f\"train:{df_train.shape[0]}, valid:{df_valid.shape[0]}, test:{df_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471c43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.reset_index().reset_index().rename({\"index\":\"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56c7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(labels=\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be19de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns={\"level_0\":\"index\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91354dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>phash</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>subset</th>\n",
       "      <th>artist_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Naive_Art_Primitivism/pablo-picasso_jug-with-h...</td>\n",
       "      <td>pablo picasso</td>\n",
       "      <td>['Naive Art Primitivism']</td>\n",
       "      <td>jug-with-handle-1954</td>\n",
       "      <td>c8263591cb59b567</td>\n",
       "      <td>1382</td>\n",
       "      <td>2132</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Impressionism/henri-matisse_blue-pot-and-lemon...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Impressionism']</td>\n",
       "      <td>blue-pot-and-lemon-1897</td>\n",
       "      <td>8c8ca5955e6a639b</td>\n",
       "      <td>1668</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Realism/nicholas-roerich_the-kremlin-tower-of-...</td>\n",
       "      <td>nicholas roerich</td>\n",
       "      <td>['Realism']</td>\n",
       "      <td>the-kremlin-tower-of-novgorod-1903</td>\n",
       "      <td>f6d6b6b6b6048425</td>\n",
       "      <td>1382</td>\n",
       "      <td>1539</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Realism/ivan-shishkin_polesye.jpg</td>\n",
       "      <td>ivan shishkin</td>\n",
       "      <td>['Realism']</td>\n",
       "      <td>polesye</td>\n",
       "      <td>83ed70178ee36e18</td>\n",
       "      <td>2314</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Post_Impressionism/vincent-van-gogh_still-life...</td>\n",
       "      <td>vincent van gogh</td>\n",
       "      <td>['Post Impressionism']</td>\n",
       "      <td>still-life-with-apples-1887</td>\n",
       "      <td>87e4b097c4e80fd5</td>\n",
       "      <td>1935</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           filename            artist  \\\n",
       "0      0  Naive_Art_Primitivism/pablo-picasso_jug-with-h...     pablo picasso   \n",
       "1      1  Impressionism/henri-matisse_blue-pot-and-lemon...     henri matisse   \n",
       "2      2  Realism/nicholas-roerich_the-kremlin-tower-of-...  nicholas roerich   \n",
       "3      3                  Realism/ivan-shishkin_polesye.jpg     ivan shishkin   \n",
       "4      4  Post_Impressionism/vincent-van-gogh_still-life...  vincent van gogh   \n",
       "\n",
       "                       genre                         description  \\\n",
       "0  ['Naive Art Primitivism']                jug-with-handle-1954   \n",
       "1          ['Impressionism']             blue-pot-and-lemon-1897   \n",
       "2                ['Realism']  the-kremlin-tower-of-novgorod-1903   \n",
       "3                ['Realism']                             polesye   \n",
       "4     ['Post Impressionism']         still-life-with-apples-1887   \n",
       "\n",
       "              phash  width  height  genre_count subset  artist_class  \n",
       "0  c8263591cb59b567   1382    2132            1  train            17  \n",
       "1  8c8ca5955e6a639b   1668    1382            1  train             9  \n",
       "2  f6d6b6b6b6048425   1382    1539            1  train            16  \n",
       "3  83ed70178ee36e18   2314    1382            1  train            12  \n",
       "4  87e4b097c4e80fd5   1935    1382            1  train            24  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b71a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>phash</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>subset</th>\n",
       "      <th>artist_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_blue-nude...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>blue-nude-1952</td>\n",
       "      <td>afbcd133d0ccc069</td>\n",
       "      <td>1382</td>\n",
       "      <td>1769</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_blue-nude...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>blue-nude</td>\n",
       "      <td>ff58d824d109cc6e</td>\n",
       "      <td>1382</td>\n",
       "      <td>2145</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_cut-outs-...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>cut-outs-1</td>\n",
       "      <td>b2cf336117ca8713</td>\n",
       "      <td>2092</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_cut-outs.jpg</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>cut-outs</td>\n",
       "      <td>bff3c8b6c0c9c08c</td>\n",
       "      <td>2082</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_la-gerbe-...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>la-gerbe-1953</td>\n",
       "      <td>acbccdc290b3db05</td>\n",
       "      <td>1675</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename         artist  \\\n",
       "0  Abstract_Expressionism/henri-matisse_blue-nude...  henri matisse   \n",
       "1  Abstract_Expressionism/henri-matisse_blue-nude...  henri matisse   \n",
       "2  Abstract_Expressionism/henri-matisse_cut-outs-...  henri matisse   \n",
       "3  Abstract_Expressionism/henri-matisse_cut-outs.jpg  henri matisse   \n",
       "4  Abstract_Expressionism/henri-matisse_la-gerbe-...  henri matisse   \n",
       "\n",
       "                        genre     description             phash  width  \\\n",
       "0  ['Abstract Expressionism']  blue-nude-1952  afbcd133d0ccc069   1382   \n",
       "1  ['Abstract Expressionism']       blue-nude  ff58d824d109cc6e   1382   \n",
       "2  ['Abstract Expressionism']      cut-outs-1  b2cf336117ca8713   2092   \n",
       "3  ['Abstract Expressionism']        cut-outs  bff3c8b6c0c9c08c   2082   \n",
       "4  ['Abstract Expressionism']   la-gerbe-1953  acbccdc290b3db05   1675   \n",
       "\n",
       "   height  genre_count subset  artist_class  \n",
       "0    1769            1   test             9  \n",
       "1    2145            1   test             9  \n",
       "2    1382            1   test             9  \n",
       "3    1382            1   test             9  \n",
       "4    1382            1   test             9  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57259e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam): # size : [B, C, W, H]\n",
    "    W = size[2] # 이미지의 width\n",
    "    H = size[3] # 이미지의 height\n",
    "    cut_rat = np.sqrt(1. - lam)  # 패치 크기의 비율 정하기\n",
    "    cut_w = np.int32(W * cut_rat)  # 패치의 너비\n",
    "    cut_h = np.int32(H * cut_rat)  # 패치의 높이\n",
    "\n",
    "    # uniform\n",
    "    # 기존 이미지의 크기에서 랜덤하게 값을 가져옵니다.(중간 좌표 추출)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    # 패치 부분에 대한 좌표값을 추출합니다.\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f51a4f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    ds_path = \"./archive/\"\n",
    "    filenames = [ f\"{ds_path}/{filename}\" for filename in  df[\"filename\"].values]\n",
    "    labels = [artist for artist in df[\"artist_class\"]]\n",
    "    #ds = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    #return ds\n",
    "    return filenames,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb37ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths, train_labels = get_data(df_train)\n",
    "val_img_paths, val_labels = get_data(df_valid)\n",
    "test_img_paths, test_labels = get_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a4799df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Data Imbalance 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e3995d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_class\n",
       "0      444\n",
       "1      339\n",
       "2      255\n",
       "3      474\n",
       "4      293\n",
       "5      715\n",
       "6      326\n",
       "7      297\n",
       "8      403\n",
       "9      263\n",
       "10     289\n",
       "11     309\n",
       "12     279\n",
       "13     419\n",
       "14     410\n",
       "15     309\n",
       "16     973\n",
       "17     409\n",
       "18     310\n",
       "19     748\n",
       "20     495\n",
       "21     277\n",
       "22     416\n",
       "23     258\n",
       "24    1012\n",
       "Name: artist_class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('artist_class')['artist_class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "179356e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = list(df_train.groupby('artist_class')['artist_class'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04cb0064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[444,\n",
       " 339,\n",
       " 255,\n",
       " 474,\n",
       " 293,\n",
       " 715,\n",
       " 326,\n",
       " 297,\n",
       " 403,\n",
       " 263,\n",
       " 289,\n",
       " 309,\n",
       " 279,\n",
       " 419,\n",
       " 410,\n",
       " 309,\n",
       " 973,\n",
       " 409,\n",
       " 310,\n",
       " 748,\n",
       " 495,\n",
       " 277,\n",
       " 416,\n",
       " 258,\n",
       " 1012]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016702aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "albrecht durer            444\n",
       "boris kustodiev           339\n",
       "camille corot             255\n",
       "camille pissarro          474\n",
       "childe hassam             293\n",
       "claude monet              715\n",
       "edgar degas               326\n",
       "eugene boudin             297\n",
       "gustave dore              403\n",
       "henri matisse             263\n",
       "ilya repin                289\n",
       "ivan aivazovsky           309\n",
       "ivan shishkin             279\n",
       "john singer sargent       419\n",
       "marc chagall              410\n",
       "martiros saryan           309\n",
       "nicholas roerich          973\n",
       "pablo picasso             409\n",
       "paul cezanne              310\n",
       "pierre auguste renoir     748\n",
       "pyotr konchalovsky        495\n",
       "raphael kirchner          277\n",
       "rembrandt                 416\n",
       "salvador dali             258\n",
       "vincent van gogh         1012\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(\"artist\")['artist'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15e86729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17,\n",
       " 9,\n",
       " 16,\n",
       " 12,\n",
       " 24,\n",
       " 8,\n",
       " 16,\n",
       " 10,\n",
       " 19,\n",
       " 2,\n",
       " 22,\n",
       " 19,\n",
       " 24,\n",
       " 13,\n",
       " 24,\n",
       " 22,\n",
       " 8,\n",
       " 5,\n",
       " 17,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 14,\n",
       " 19,\n",
       " 0,\n",
       " 16,\n",
       " 23,\n",
       " 13,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 16,\n",
       " 24,\n",
       " 2,\n",
       " 18,\n",
       " 12,\n",
       " 19,\n",
       " 20,\n",
       " 4,\n",
       " 21,\n",
       " 20,\n",
       " 20,\n",
       " 11,\n",
       " 17,\n",
       " 21,\n",
       " 10,\n",
       " 19,\n",
       " 5,\n",
       " 3,\n",
       " 21,\n",
       " 13,\n",
       " 6,\n",
       " 17,\n",
       " 3,\n",
       " 1,\n",
       " 14,\n",
       " 24,\n",
       " 16,\n",
       " 24,\n",
       " 8,\n",
       " 14,\n",
       " 10,\n",
       " 8,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 4,\n",
       " 17,\n",
       " 19,\n",
       " 10,\n",
       " 24,\n",
       " 20,\n",
       " 0,\n",
       " 0,\n",
       " 20,\n",
       " 9,\n",
       " 24,\n",
       " 8,\n",
       " 12,\n",
       " 14,\n",
       " 5,\n",
       " 24,\n",
       " 3,\n",
       " 17,\n",
       " 13,\n",
       " 24,\n",
       " 7,\n",
       " 5,\n",
       " 13,\n",
       " 20,\n",
       " 0,\n",
       " 19,\n",
       " 16,\n",
       " 13,\n",
       " 20,\n",
       " 20,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 19,\n",
       " 24,\n",
       " 3,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 8,\n",
       " 12,\n",
       " 19,\n",
       " 9,\n",
       " 20,\n",
       " 0,\n",
       " 17,\n",
       " 22,\n",
       " 2,\n",
       " 5,\n",
       " 10,\n",
       " 8,\n",
       " 22,\n",
       " 9,\n",
       " 19,\n",
       " 10,\n",
       " 19,\n",
       " 19,\n",
       " 3,\n",
       " 16,\n",
       " 10,\n",
       " 1,\n",
       " 10,\n",
       " 23,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 21,\n",
       " 22,\n",
       " 11,\n",
       " 23,\n",
       " 16,\n",
       " 19,\n",
       " 24,\n",
       " 5,\n",
       " 2,\n",
       " 18,\n",
       " 17,\n",
       " 13,\n",
       " 19,\n",
       " 15,\n",
       " 18,\n",
       " 4,\n",
       " 16,\n",
       " 24,\n",
       " 19,\n",
       " 24,\n",
       " 19,\n",
       " 24,\n",
       " 5,\n",
       " 1,\n",
       " 14,\n",
       " 1,\n",
       " 14,\n",
       " 20,\n",
       " 2,\n",
       " 21,\n",
       " 12,\n",
       " 21,\n",
       " 23,\n",
       " 22,\n",
       " 19,\n",
       " 16,\n",
       " 20,\n",
       " 24,\n",
       " 24,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 18,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 11,\n",
       " 13,\n",
       " 24,\n",
       " 0,\n",
       " 6,\n",
       " 11,\n",
       " 9,\n",
       " 6,\n",
       " 24,\n",
       " 4,\n",
       " 0,\n",
       " 24,\n",
       " 12,\n",
       " 6,\n",
       " 21,\n",
       " 2,\n",
       " 19,\n",
       " 22,\n",
       " 24,\n",
       " 7,\n",
       " 10,\n",
       " 24,\n",
       " 3,\n",
       " 24,\n",
       " 18,\n",
       " 5,\n",
       " 16,\n",
       " 14,\n",
       " 19,\n",
       " 11,\n",
       " 20,\n",
       " 5,\n",
       " 19,\n",
       " 16,\n",
       " 19,\n",
       " 12,\n",
       " 23,\n",
       " 22,\n",
       " 19,\n",
       " 3,\n",
       " 16,\n",
       " 14,\n",
       " 17,\n",
       " 21,\n",
       " 18,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 16,\n",
       " 24,\n",
       " 12,\n",
       " 16,\n",
       " 16,\n",
       " 14,\n",
       " 13,\n",
       " 0,\n",
       " 24,\n",
       " 12,\n",
       " 0,\n",
       " 5,\n",
       " 13,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 16,\n",
       " 24,\n",
       " 3,\n",
       " 21,\n",
       " 13,\n",
       " 14,\n",
       " 12,\n",
       " 20,\n",
       " 22,\n",
       " 14,\n",
       " 0,\n",
       " 11,\n",
       " 19,\n",
       " 24,\n",
       " 14,\n",
       " 10,\n",
       " 21,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 18,\n",
       " 16,\n",
       " 1,\n",
       " 24,\n",
       " 0,\n",
       " 9,\n",
       " 19,\n",
       " 19,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 24,\n",
       " 10,\n",
       " 4,\n",
       " 18,\n",
       " 16,\n",
       " 8,\n",
       " 22,\n",
       " 15,\n",
       " 3,\n",
       " 18,\n",
       " 14,\n",
       " 24,\n",
       " 5,\n",
       " 14,\n",
       " 23,\n",
       " 19,\n",
       " 23,\n",
       " 24,\n",
       " 2,\n",
       " 5,\n",
       " 24,\n",
       " 22,\n",
       " 0,\n",
       " 16,\n",
       " 20,\n",
       " 3,\n",
       " 17,\n",
       " 23,\n",
       " 17,\n",
       " 19,\n",
       " 16,\n",
       " 10,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 6,\n",
       " 17,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 24,\n",
       " 16,\n",
       " 20,\n",
       " 4,\n",
       " 20,\n",
       " 15,\n",
       " 11,\n",
       " 24,\n",
       " 19,\n",
       " 6,\n",
       " 16,\n",
       " 7,\n",
       " 24,\n",
       " 19,\n",
       " 16,\n",
       " 4,\n",
       " 24,\n",
       " 20,\n",
       " 10,\n",
       " 24,\n",
       " 21,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 17,\n",
       " 24,\n",
       " 24,\n",
       " 10,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 20,\n",
       " 13,\n",
       " 11,\n",
       " 16,\n",
       " 18,\n",
       " 14,\n",
       " 8,\n",
       " 23,\n",
       " 24,\n",
       " 5,\n",
       " 13,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 24,\n",
       " 17,\n",
       " 13,\n",
       " 22,\n",
       " 16,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 17,\n",
       " 16,\n",
       " 24,\n",
       " 13,\n",
       " 21,\n",
       " 4,\n",
       " 5,\n",
       " 21,\n",
       " 20,\n",
       " 3,\n",
       " 1,\n",
       " 16,\n",
       " 24,\n",
       " 20,\n",
       " 24,\n",
       " 22,\n",
       " 18,\n",
       " 24,\n",
       " 23,\n",
       " 16,\n",
       " 23,\n",
       " 3,\n",
       " 18,\n",
       " 22,\n",
       " 14,\n",
       " 12,\n",
       " 20,\n",
       " 6,\n",
       " 16,\n",
       " 13,\n",
       " 21,\n",
       " 9,\n",
       " 24,\n",
       " 3,\n",
       " 1,\n",
       " 18,\n",
       " 10,\n",
       " 15,\n",
       " 3,\n",
       " 13,\n",
       " 18,\n",
       " 16,\n",
       " 17,\n",
       " 20,\n",
       " 16,\n",
       " 24,\n",
       " 13,\n",
       " 7,\n",
       " 20,\n",
       " 6,\n",
       " 22,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 22,\n",
       " 12,\n",
       " 5,\n",
       " 21,\n",
       " 16,\n",
       " 24,\n",
       " 20,\n",
       " 24,\n",
       " 16,\n",
       " 17,\n",
       " 24,\n",
       " 18,\n",
       " 5,\n",
       " 19,\n",
       " 14,\n",
       " 20,\n",
       " 23,\n",
       " 13,\n",
       " 11,\n",
       " 1,\n",
       " 15,\n",
       " 13,\n",
       " 24,\n",
       " 13,\n",
       " 9,\n",
       " 4,\n",
       " 19,\n",
       " 11,\n",
       " 24,\n",
       " 11,\n",
       " 8,\n",
       " 2,\n",
       " 24,\n",
       " 7,\n",
       " 18,\n",
       " 4,\n",
       " 16,\n",
       " 13,\n",
       " 23,\n",
       " 5,\n",
       " 15,\n",
       " 11,\n",
       " 16,\n",
       " 23,\n",
       " 11,\n",
       " 21,\n",
       " 16,\n",
       " 20,\n",
       " 2,\n",
       " 19,\n",
       " 23,\n",
       " 19,\n",
       " 1,\n",
       " 10,\n",
       " 16,\n",
       " 5,\n",
       " 9,\n",
       " 12,\n",
       " 18,\n",
       " 8,\n",
       " 16,\n",
       " 18,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 20,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 23,\n",
       " 22,\n",
       " 2,\n",
       " 16,\n",
       " 5,\n",
       " 18,\n",
       " 15,\n",
       " 19,\n",
       " 14,\n",
       " 13,\n",
       " 0,\n",
       " 8,\n",
       " 17,\n",
       " 23,\n",
       " 20,\n",
       " 1,\n",
       " 20,\n",
       " 21,\n",
       " 24,\n",
       " 18,\n",
       " 0,\n",
       " 16,\n",
       " 12,\n",
       " 11,\n",
       " 3,\n",
       " 15,\n",
       " 16,\n",
       " 19,\n",
       " 5,\n",
       " 2,\n",
       " 11,\n",
       " 24,\n",
       " 24,\n",
       " 6,\n",
       " 16,\n",
       " 13,\n",
       " 22,\n",
       " 24,\n",
       " 5,\n",
       " 15,\n",
       " 19,\n",
       " 22,\n",
       " 6,\n",
       " 2,\n",
       " 11,\n",
       " 16,\n",
       " 3,\n",
       " 15,\n",
       " 4,\n",
       " 20,\n",
       " 3,\n",
       " 23,\n",
       " 6,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 9,\n",
       " 12,\n",
       " 19,\n",
       " 13,\n",
       " 19,\n",
       " 21,\n",
       " 24,\n",
       " 24,\n",
       " 23,\n",
       " 15,\n",
       " 5,\n",
       " 16,\n",
       " 6,\n",
       " 5,\n",
       " 16,\n",
       " 1,\n",
       " 19,\n",
       " 6,\n",
       " 3,\n",
       " 23,\n",
       " 24,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 15,\n",
       " 3,\n",
       " 22,\n",
       " 4,\n",
       " 22,\n",
       " 22,\n",
       " 0,\n",
       " 7,\n",
       " 22,\n",
       " 10,\n",
       " 19,\n",
       " 5,\n",
       " 16,\n",
       " 24,\n",
       " 17,\n",
       " 22,\n",
       " 19,\n",
       " 3,\n",
       " 22,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 24,\n",
       " 22,\n",
       " 24,\n",
       " 17,\n",
       " 1,\n",
       " 17,\n",
       " 16,\n",
       " 19,\n",
       " 3,\n",
       " 16,\n",
       " 19,\n",
       " 24,\n",
       " 5,\n",
       " 10,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 23,\n",
       " 5,\n",
       " 14,\n",
       " 14,\n",
       " 10,\n",
       " 23,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 18,\n",
       " 16,\n",
       " 24,\n",
       " 23,\n",
       " 23,\n",
       " 22,\n",
       " 13,\n",
       " 20,\n",
       " 17,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 20,\n",
       " 0,\n",
       " 16,\n",
       " 14,\n",
       " 1,\n",
       " 24,\n",
       " 6,\n",
       " 16,\n",
       " 9,\n",
       " 16,\n",
       " 18,\n",
       " 8,\n",
       " 22,\n",
       " 24,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 16,\n",
       " 24,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 24,\n",
       " 19,\n",
       " 5,\n",
       " 24,\n",
       " 18,\n",
       " 20,\n",
       " 3,\n",
       " 10,\n",
       " 17,\n",
       " 24,\n",
       " 14,\n",
       " 4,\n",
       " 4,\n",
       " 18,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 24,\n",
       " 16,\n",
       " 22,\n",
       " 4,\n",
       " 20,\n",
       " 17,\n",
       " 18,\n",
       " 22,\n",
       " 5,\n",
       " 3,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 5,\n",
       " 19,\n",
       " 7,\n",
       " 7,\n",
       " 20,\n",
       " 20,\n",
       " 22,\n",
       " 24,\n",
       " 14,\n",
       " 23,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 17,\n",
       " 20,\n",
       " 12,\n",
       " 24,\n",
       " 16,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 13,\n",
       " 9,\n",
       " 13,\n",
       " 20,\n",
       " 16,\n",
       " 1,\n",
       " 19,\n",
       " 5,\n",
       " 21,\n",
       " 17,\n",
       " 5,\n",
       " 11,\n",
       " 19,\n",
       " 23,\n",
       " 19,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 16,\n",
       " 5,\n",
       " 8,\n",
       " 17,\n",
       " 3,\n",
       " 4,\n",
       " 24,\n",
       " 16,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 24,\n",
       " 19,\n",
       " 20,\n",
       " 6,\n",
       " 5,\n",
       " 18,\n",
       " 16,\n",
       " 19,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 11,\n",
       " 6,\n",
       " 20,\n",
       " 11,\n",
       " 24,\n",
       " 1,\n",
       " 16,\n",
       " 5,\n",
       " 19,\n",
       " 5,\n",
       " 17,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 12,\n",
       " 5,\n",
       " 13,\n",
       " 6,\n",
       " 20,\n",
       " 20,\n",
       " 6,\n",
       " 20,\n",
       " 16,\n",
       " 17,\n",
       " 3,\n",
       " 16,\n",
       " 5,\n",
       " 8,\n",
       " 17,\n",
       " 14,\n",
       " 5,\n",
       " 14,\n",
       " 16,\n",
       " 2,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 16,\n",
       " 16,\n",
       " 24,\n",
       " 5,\n",
       " 16,\n",
       " 10,\n",
       " 24,\n",
       " 0,\n",
       " 21,\n",
       " 16,\n",
       " 15,\n",
       " 12,\n",
       " 21,\n",
       " 22,\n",
       " 16,\n",
       " 1,\n",
       " 23,\n",
       " 18,\n",
       " 11,\n",
       " 24,\n",
       " 20,\n",
       " 3,\n",
       " 24,\n",
       " 11,\n",
       " 12,\n",
       " 9,\n",
       " 15,\n",
       " 3,\n",
       " 15,\n",
       " 7,\n",
       " 18,\n",
       " 22,\n",
       " 15,\n",
       " 18,\n",
       " 19,\n",
       " 3,\n",
       " 17,\n",
       " 6,\n",
       " 12,\n",
       " 19,\n",
       " 15,\n",
       " 20,\n",
       " 11,\n",
       " 9,\n",
       " 13,\n",
       " 13,\n",
       " 5,\n",
       " 5,\n",
       " 11,\n",
       " 8,\n",
       " 3,\n",
       " 20,\n",
       " 14,\n",
       " 9,\n",
       " 16,\n",
       " 21,\n",
       " 5,\n",
       " 19,\n",
       " 6,\n",
       " 3,\n",
       " 16,\n",
       " 24,\n",
       " 9,\n",
       " 13,\n",
       " 13,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 24,\n",
       " 1,\n",
       " 3,\n",
       " 20,\n",
       " 12,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 22,\n",
       " 16,\n",
       " 12,\n",
       " 6,\n",
       " 24,\n",
       " 13,\n",
       " 12,\n",
       " 4,\n",
       " 14,\n",
       " 6,\n",
       " 24,\n",
       " 23,\n",
       " 14,\n",
       " 14,\n",
       " 17,\n",
       " 24,\n",
       " 20,\n",
       " 2,\n",
       " 24,\n",
       " 5,\n",
       " 24,\n",
       " 14,\n",
       " 16,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 17,\n",
       " 22,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 20,\n",
       " 16,\n",
       " 19,\n",
       " 3,\n",
       " 10,\n",
       " 19,\n",
       " 5,\n",
       " 8,\n",
       " 19,\n",
       " 21,\n",
       " 16,\n",
       " 10,\n",
       " 11,\n",
       " 5,\n",
       " 13,\n",
       " 21,\n",
       " 11,\n",
       " 8,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 2,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 15,\n",
       " 9,\n",
       " 21,\n",
       " 24,\n",
       " 16,\n",
       " 10,\n",
       " 17,\n",
       " 7,\n",
       " 19,\n",
       " 14,\n",
       " 16,\n",
       " 11,\n",
       " 24,\n",
       " 24,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 16,\n",
       " 21,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 24,\n",
       " 14,\n",
       " 7,\n",
       " 22,\n",
       " 6,\n",
       " 18,\n",
       " 11,\n",
       " 20,\n",
       " 20,\n",
       " 3,\n",
       " 24,\n",
       " 14,\n",
       " 17,\n",
       " 13,\n",
       " 2,\n",
       " 0,\n",
       " 15,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 19,\n",
       " 7,\n",
       " 5,\n",
       " 10,\n",
       " 22,\n",
       " 22,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 24,\n",
       " 3,\n",
       " 23,\n",
       " 17,\n",
       " 24,\n",
       " 8,\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "858812b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights(labels, nclasses):\n",
    "    labels = np.array(labels) \n",
    "    weight_arr = np.zeros_like(labels) \n",
    "    \n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    for cls in range(nclasses):\n",
    "        weight_arr = np.where(labels == cls, 1/counts[cls], weight_arr)\n",
    "        # 각 클래스의의 인덱스를 산출하여 해당 클래스 개수의 역수를 확률로 할당한다.\n",
    "        # 이를 통해 각 클래스의 전체 가중치를 동일하게 한다.\n",
    " \n",
    "    return weight_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74eabd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0024, 0.0038, 0.0010,  ..., 0.0010, 0.0031, 0.0036], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimsoyeon/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/_tensor_str.py:125: UserWarning: 1MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1676880691697/work/aten/src/ATen/native/mps/operations/ReduceOps.mm:1263.)\n",
      "  nonzero_finite_min = tensor_totype(nonzero_finite_abs.min())\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "w = make_weights(train_labels,25)\n",
    "w= torch.FloatTensor(w).to(\"mps\")\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46a32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = np.array(image)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc313479",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'BATCH_SIZE':16,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "764bcc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2),\n",
    "                            A.RandomCrop(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.HorizontalFlip(p=0.5),\n",
    "                            A.VerticalFlip(p=0.5),\n",
    "                            A.ShiftScaleRotate(p=0.5),\n",
    "                            A.OneOf([\n",
    "                                A.CLAHE(clip_limit=2),\n",
    "                                A.RandomBrightnessContrast(),\n",
    "                            ], p=0.3),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, \n",
    "                                        always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2),\n",
    "                            A.RandomCrop(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, \n",
    "                                        always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, \n",
    "                                        always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ce6c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_img_paths, train_labels, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n",
    "\n",
    "val_dataset = CustomDataset(val_img_paths, val_labels, val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc60df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True).to(\"mps\")\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ef264da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.conv1.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bd7e132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e5cbeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /Users/kimsoyeon/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "842d07f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                   [-1, 25]          51,225\n",
      "================================================================\n",
      "Total params: 23,559,257\n",
      "Trainable params: 23,559,257\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.87\n",
      "Estimated Total Size (MB): 377.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary as summary\n",
    "\n",
    "summary(resnet.to(\"cpu\"), (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a364f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([64, 3, 7, 7])\n",
      "bn1.weight torch.Size([64])\n",
      "bn1.bias torch.Size([64])\n",
      "layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "layer1.0.bn1.weight torch.Size([64])\n",
      "layer1.0.bn1.bias torch.Size([64])\n",
      "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight torch.Size([64])\n",
      "layer1.0.bn2.bias torch.Size([64])\n",
      "layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.bn3.weight torch.Size([256])\n",
      "layer1.0.bn3.bias torch.Size([256])\n",
      "layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.downsample.1.weight torch.Size([256])\n",
      "layer1.0.downsample.1.bias torch.Size([256])\n",
      "layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.1.bn1.weight torch.Size([64])\n",
      "layer1.1.bn1.bias torch.Size([64])\n",
      "layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight torch.Size([64])\n",
      "layer1.1.bn2.bias torch.Size([64])\n",
      "layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.1.bn3.weight torch.Size([256])\n",
      "layer1.1.bn3.bias torch.Size([256])\n",
      "layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.2.bn1.weight torch.Size([64])\n",
      "layer1.2.bn1.bias torch.Size([64])\n",
      "layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.2.bn2.weight torch.Size([64])\n",
      "layer1.2.bn2.bias torch.Size([64])\n",
      "layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.2.bn3.weight torch.Size([256])\n",
      "layer1.2.bn3.bias torch.Size([256])\n",
      "layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "layer2.0.bn1.weight torch.Size([128])\n",
      "layer2.0.bn1.bias torch.Size([128])\n",
      "layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight torch.Size([128])\n",
      "layer2.0.bn2.bias torch.Size([128])\n",
      "layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.0.bn3.weight torch.Size([512])\n",
      "layer2.0.bn3.bias torch.Size([512])\n",
      "layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "layer2.0.downsample.1.weight torch.Size([512])\n",
      "layer2.0.downsample.1.bias torch.Size([512])\n",
      "layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.1.bn1.weight torch.Size([128])\n",
      "layer2.1.bn1.bias torch.Size([128])\n",
      "layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight torch.Size([128])\n",
      "layer2.1.bn2.bias torch.Size([128])\n",
      "layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.1.bn3.weight torch.Size([512])\n",
      "layer2.1.bn3.bias torch.Size([512])\n",
      "layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.2.bn1.weight torch.Size([128])\n",
      "layer2.2.bn1.bias torch.Size([128])\n",
      "layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.2.bn2.weight torch.Size([128])\n",
      "layer2.2.bn2.bias torch.Size([128])\n",
      "layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.2.bn3.weight torch.Size([512])\n",
      "layer2.2.bn3.bias torch.Size([512])\n",
      "layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.3.bn1.weight torch.Size([128])\n",
      "layer2.3.bn1.bias torch.Size([128])\n",
      "layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.3.bn2.weight torch.Size([128])\n",
      "layer2.3.bn2.bias torch.Size([128])\n",
      "layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.3.bn3.weight torch.Size([512])\n",
      "layer2.3.bn3.bias torch.Size([512])\n",
      "layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "layer3.0.bn1.weight torch.Size([256])\n",
      "layer3.0.bn1.bias torch.Size([256])\n",
      "layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight torch.Size([256])\n",
      "layer3.0.bn2.bias torch.Size([256])\n",
      "layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.0.bn3.weight torch.Size([1024])\n",
      "layer3.0.bn3.bias torch.Size([1024])\n",
      "layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "layer3.0.downsample.1.weight torch.Size([1024])\n",
      "layer3.0.downsample.1.bias torch.Size([1024])\n",
      "layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.1.bn1.weight torch.Size([256])\n",
      "layer3.1.bn1.bias torch.Size([256])\n",
      "layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight torch.Size([256])\n",
      "layer3.1.bn2.bias torch.Size([256])\n",
      "layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.1.bn3.weight torch.Size([1024])\n",
      "layer3.1.bn3.bias torch.Size([1024])\n",
      "layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.2.bn1.weight torch.Size([256])\n",
      "layer3.2.bn1.bias torch.Size([256])\n",
      "layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.2.bn2.weight torch.Size([256])\n",
      "layer3.2.bn2.bias torch.Size([256])\n",
      "layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.2.bn3.weight torch.Size([1024])\n",
      "layer3.2.bn3.bias torch.Size([1024])\n",
      "layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.3.bn1.weight torch.Size([256])\n",
      "layer3.3.bn1.bias torch.Size([256])\n",
      "layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.3.bn2.weight torch.Size([256])\n",
      "layer3.3.bn2.bias torch.Size([256])\n",
      "layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.3.bn3.weight torch.Size([1024])\n",
      "layer3.3.bn3.bias torch.Size([1024])\n",
      "layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.4.bn1.weight torch.Size([256])\n",
      "layer3.4.bn1.bias torch.Size([256])\n",
      "layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.4.bn2.weight torch.Size([256])\n",
      "layer3.4.bn2.bias torch.Size([256])\n",
      "layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.4.bn3.weight torch.Size([1024])\n",
      "layer3.4.bn3.bias torch.Size([1024])\n",
      "layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.5.bn1.weight torch.Size([256])\n",
      "layer3.5.bn1.bias torch.Size([256])\n",
      "layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.5.bn2.weight torch.Size([256])\n",
      "layer3.5.bn2.bias torch.Size([256])\n",
      "layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.5.bn3.weight torch.Size([1024])\n",
      "layer3.5.bn3.bias torch.Size([1024])\n",
      "layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "layer4.0.bn1.weight torch.Size([512])\n",
      "layer4.0.bn1.bias torch.Size([512])\n",
      "layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight torch.Size([512])\n",
      "layer4.0.bn2.bias torch.Size([512])\n",
      "layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.0.bn3.weight torch.Size([2048])\n",
      "layer4.0.bn3.bias torch.Size([2048])\n",
      "layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "layer4.0.downsample.1.weight torch.Size([2048])\n",
      "layer4.0.downsample.1.bias torch.Size([2048])\n",
      "layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.1.bn1.weight torch.Size([512])\n",
      "layer4.1.bn1.bias torch.Size([512])\n",
      "layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight torch.Size([512])\n",
      "layer4.1.bn2.bias torch.Size([512])\n",
      "layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.1.bn3.weight torch.Size([2048])\n",
      "layer4.1.bn3.bias torch.Size([2048])\n",
      "layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.2.bn1.weight torch.Size([512])\n",
      "layer4.2.bn1.bias torch.Size([512])\n",
      "layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.2.bn2.weight torch.Size([512])\n",
      "layer4.2.bn2.bias torch.Size([512])\n",
      "layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.bn3.weight torch.Size([2048])\n",
      "layer4.2.bn3.bias torch.Size([2048])\n",
      "fc.weight torch.Size([25, 2048])\n",
      "fc.bias torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "for name, param in resnet.named_parameters():\n",
    "    print(name,param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11610912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict_path = './checkpoint/best_model_weight.pt'\n",
    "weights=torch.load(state_dict_path,map_location=torch.device('cpu'))\n",
    "resnet.load_state_dict(weights['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11b6de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ins = class_count    # 실제 클래스 수 \n",
    " \n",
    "weights = [1 - (x/sum(num_ins)) for x in num_ins]\n",
    "class_weights = torch.FloatTensor(weights).to(\"mps\")\n",
    " \n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54571f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Imbalance 문제 해결 위해 CrossEntropyLoss에 Weight 적용\n",
    "# criterion = nn.CrossEntropyLoss(weight=w)\n",
    "# 모든 매개변수들이 최적화되었는지 관찰\n",
    "optimizer_ft = optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93734263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, saved_dir):\n",
    "    os.makedirs(saved_dir, exist_ok=True)\n",
    "    check_point = {\n",
    "        'net2' : model.state_dict()\n",
    "    }\n",
    "    torch.save(check_point, saved_dir+'/best_model_weight_conv1,2,3,4,5_freeze.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23be2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "def eval_model(model_ft, data_loader, device):\n",
    "  model_ft.eval()\n",
    "\n",
    "  best_acc = 0.0\n",
    "    \n",
    "  ys = []\n",
    "  ypreds = []\n",
    "  for x, y in data_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      _, y_pred = model_ft(x).max(1)\n",
    "    ys.append(y)\n",
    "    ypreds.append(y_pred)\n",
    "\n",
    "  ys = torch.cat(ys)\n",
    "  ypreds = torch.cat(ypreds)\n",
    "\n",
    "  acc = ((ys == ypreds).float().sum() / len(ys)) * 100\n",
    "\n",
    "  if best_acc < acc:\n",
    "        save_model(model_ft, './checkpoint')\n",
    "        print('Succeed save the model')\n",
    "        best_acc=acc\n",
    "        \n",
    "  \n",
    "  return acc.item()\n",
    "\n",
    "\n",
    "def train_model(model_ft,train_loader, val_loader, only_fc,\n",
    "                optimizer_cls,\n",
    "                loss_fn,\n",
    "                n_iter=10, device='cpu'):\n",
    "  train_losses = []\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "\n",
    "  if only_fc:\n",
    "    optimizer = optimizer_cls\n",
    "  \n",
    "  else:\n",
    "    optimizer = optimizer_cls(model_ft.parameters())\n",
    "\n",
    "  for epoch in range(n_iter):\n",
    "    running_loss = 0.0\n",
    "    model_ft.train()\n",
    "    n = 0\n",
    "    n_acc = 0\n",
    "\n",
    "    for i, (xx, yy) in tqdm(enumerate(train_loader), total= len(train_loader)):\n",
    "      yy = torch.from_numpy(np.asarray(yy))\n",
    "      xx = xx.to(device)\n",
    "      yy = yy.to(device)\n",
    "      optimizer.zero_grad()\n",
    "        # cutmix\n",
    "      if np.random.random()>0.5:\n",
    "        X, y = xx,yy\n",
    "        lam = np.random.beta(1.0, 1.0)\n",
    "        rand_index = torch.randperm(X.size()[0]).to(device)\n",
    "        target_a = y\n",
    "        target_b = y[rand_index]            \n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(X.size(), lam)\n",
    "        X[:, :, bbx1:bbx2, bby1:bby2] = X[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (X.size()[-1] * X.size()[-2]))\n",
    "        h = model_ft(X)\n",
    "        loss = loss_fn(h, target_a) * lam + loss_fn(h, target_b) * (1. - lam)\n",
    "      else:\n",
    "        h = model_ft(xx)\n",
    "        loss = loss_fn(h,yy)\n",
    "        \n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "      n += len(xx)\n",
    "      _,y_pred = h.max(1)\n",
    "      n_acc += (yy == y_pred).float().sum().item()\n",
    "    \n",
    "    if epoch%1 == 0:\n",
    "        print(\"lr: \", optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    train_losses.append(running_loss/i)\n",
    "    \n",
    "    train_acc.append(n_acc / n)\n",
    "\n",
    "    val_acc.append(eval_model(model_ft, val_loader, device))\n",
    "\n",
    "    print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41740817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668d933d948f450b8f9162843e1949e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "0 1.487320720392136 0.6075559701492538 72.91667175292969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9764997e0b14a40a45e5be3b0762517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "1 1.4937731658842175 0.6098880597014925 73.88258361816406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792a645dee8e4c878992467125cedb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "2 1.4650821403804917 0.6125932835820895 74.20454406738281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef55344fe0a406a8a8fc66ad63c7489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "3 1.4668791425513223 0.610634328358209 75.4734878540039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a264e23d3034b61bd9fe0fb75849dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "4 1.425129636431667 0.6199626865671641 75.03788757324219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b65ea1c3e7d47b289d6fdab71bd7db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "5 1.4271865644128867 0.6286380597014926 76.23106384277344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d0cae6095a4c218bc8baaaa295a350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "6 1.3808353577137706 0.6388992537313433 77.19697570800781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074c699738b24c0695f0dbdfdb069ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "7 1.391234059593959 0.639365671641791 77.1022720336914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff18fb64e88f431cb83e8d200bfabefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "8 1.310757457118576 0.6563432835820896 77.51893615722656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d3695ad1c84570b69b24c3f00bf095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "9 1.3488770872577245 0.6395522388059701 77.17803192138672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710996e081014a0cb2136e87c01f0222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "10 1.2683399698303064 0.6710820895522388 77.25379180908203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c50c4122444b6c9d7e3f2251f3ccbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "11 1.2775228397728617 0.6666044776119403 78.44697570800781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90f3f617d694a76944235090c0bd593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "12 1.331348257726796 0.6540111940298508 78.16288757324219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ccfc57c5934785ab5a557fe62b2cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "13 1.2869363628517174 0.6598880597014926 78.1439437866211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9baa814c8a3e485188d03c2c19b1a537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "14 1.254752264206363 0.6745335820895523 78.3712158203125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859660326b684840aaee847d47fe087d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "15 1.2535979830185215 0.6738805970149254 79.2234878540039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbe29277961484598ef5e40ea76b82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "16 1.2459679415006808 0.6779850746268656 79.01515197753906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a8b5935ccd4d709853e9768b43901f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "17 1.2480521284277664 0.6821828358208956 79.41287994384766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c8d04e2d67440eac0fc161197418e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "18 1.1678966969608013 0.7013992537313433 79.90530395507812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77275763117348b5a24ebdb0b55b840d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "19 1.196915419891989 0.6938432835820896 80.2462158203125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7c7e4b80eb4e65875dcebd7ae30a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "20 1.20523740774402 0.6834888059701493 79.65909576416016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0196231177df40ab9b2b3dfc6eac57e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "21 1.209339850864781 0.6940298507462687 80.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd45129c39f498ea89370722fc3ce73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "22 1.1799371109994181 0.6977611940298507 79.71591186523438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695803718a824a129f627694ea2911e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "23 1.1988083351576098 0.6956156716417911 80.68182373046875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e53b959c1764dd9af2772fea7d1a517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "24 1.1789564909065429 0.7113805970149254 79.90530395507812\n"
     ]
    }
   ],
   "source": [
    "resnet.to(\"mps\")\n",
    "\n",
    "train_model(resnet, train_loader, val_loader, only_fc = True, optimizer_cls=optimizer_ft,\n",
    "            loss_fn = criterion, n_iter=25, device='mps')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
