{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708d6685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>phash</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_acolman-1...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>acolman-1-1955</td>\n",
       "      <td>bebbeb018a7d80a8</td>\n",
       "      <td>1922</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_chicago-6...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>chicago-6-1961</td>\n",
       "      <td>d7d0781be51fc00e</td>\n",
       "      <td>1382</td>\n",
       "      <td>1746</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_glouceste...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>gloucester-16a-1944</td>\n",
       "      <td>9f846e5a6c639325</td>\n",
       "      <td>1382</td>\n",
       "      <td>1857</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_jerome-ar...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>jerome-arizona-1949</td>\n",
       "      <td>a5d691f85ac5e4d0</td>\n",
       "      <td>1382</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract_Expressionism/aaron-siskind_kentucky-...</td>\n",
       "      <td>aaron siskind</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>kentucky-4-1951</td>\n",
       "      <td>880df359e6b11db1</td>\n",
       "      <td>1382</td>\n",
       "      <td>1625</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename         artist  \\\n",
       "0  Abstract_Expressionism/aaron-siskind_acolman-1...  aaron siskind   \n",
       "1  Abstract_Expressionism/aaron-siskind_chicago-6...  aaron siskind   \n",
       "2  Abstract_Expressionism/aaron-siskind_glouceste...  aaron siskind   \n",
       "3  Abstract_Expressionism/aaron-siskind_jerome-ar...  aaron siskind   \n",
       "4  Abstract_Expressionism/aaron-siskind_kentucky-...  aaron siskind   \n",
       "\n",
       "                        genre          description             phash  width  \\\n",
       "0  ['Abstract Expressionism']       acolman-1-1955  bebbeb018a7d80a8   1922   \n",
       "1  ['Abstract Expressionism']       chicago-6-1961  d7d0781be51fc00e   1382   \n",
       "2  ['Abstract Expressionism']  gloucester-16a-1944  9f846e5a6c639325   1382   \n",
       "3  ['Abstract Expressionism']  jerome-arizona-1949  a5d691f85ac5e4d0   1382   \n",
       "4  ['Abstract Expressionism']      kentucky-4-1951  880df359e6b11db1   1382   \n",
       "\n",
       "   height  genre_count subset  \n",
       "0    1382            1  train  \n",
       "1    1746            1  train  \n",
       "2    1857            1  train  \n",
       "3    1849            1  train  \n",
       "4    1625            1  train  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_classes = pd.read_csv('./archive/classes.csv')\n",
    "df_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99cfbde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119\n"
     ]
    }
   ],
   "source": [
    "print(len(df_classes.groupby([\"artist\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb60f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>subset</th>\n",
       "      <th>artist</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>uncertain artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>vincent van gogh</td>\n",
       "      <td>378</td>\n",
       "      <td>1510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>nicholas roerich</td>\n",
       "      <td>363</td>\n",
       "      <td>1453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>pierre auguste renoir</td>\n",
       "      <td>280</td>\n",
       "      <td>1117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>claude monet</td>\n",
       "      <td>267</td>\n",
       "      <td>1067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>pyotr konchalovsky</td>\n",
       "      <td>185</td>\n",
       "      <td>739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>camille pissarro</td>\n",
       "      <td>177</td>\n",
       "      <td>707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>albrecht durer</td>\n",
       "      <td>166</td>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>john singer sargent</td>\n",
       "      <td>157</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>rembrandt</td>\n",
       "      <td>155</td>\n",
       "      <td>621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>marc chagall</td>\n",
       "      <td>153</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>pablo picasso</td>\n",
       "      <td>153</td>\n",
       "      <td>610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>gustave dore</td>\n",
       "      <td>151</td>\n",
       "      <td>602</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>boris kustodiev</td>\n",
       "      <td>127</td>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>edgar degas</td>\n",
       "      <td>122</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>paul cezanne</td>\n",
       "      <td>116</td>\n",
       "      <td>463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>ivan aivazovsky</td>\n",
       "      <td>116</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>martiros saryan</td>\n",
       "      <td>115</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>eugene boudin</td>\n",
       "      <td>111</td>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>childe hassam</td>\n",
       "      <td>110</td>\n",
       "      <td>437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>ilya repin</td>\n",
       "      <td>108</td>\n",
       "      <td>431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>ivan shishkin</td>\n",
       "      <td>104</td>\n",
       "      <td>416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>raphael kirchner</td>\n",
       "      <td>103</td>\n",
       "      <td>413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>henri matisse</td>\n",
       "      <td>98</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>salvador dali</td>\n",
       "      <td>96</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>camille corot</td>\n",
       "      <td>96</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "subset                 artist  test  train  uncertain artist\n",
       "1074         vincent van gogh   378   1510                 0\n",
       "809          nicholas roerich   363   1453                 0\n",
       "898     pierre auguste renoir   280   1117                 2\n",
       "190              claude monet   267   1067                 0\n",
       "917        pyotr konchalovsky   185    739                 0\n",
       "158          camille pissarro   177    707                 0\n",
       "34             albrecht durer   166    662                 0\n",
       "599       john singer sargent   157    625                 1\n",
       "932                 rembrandt   155    621                 0\n",
       "719              marc chagall   153    612                 0\n",
       "846             pablo picasso   153    610                 0\n",
       "420              gustave dore   151    602                 0\n",
       "148           boris kustodiev   127    506                 0\n",
       "252               edgar degas   122    487                 2\n",
       "859              paul cezanne   116    463                 0\n",
       "495           ivan aivazovsky   116    461                 0\n",
       "749           martiros saryan   115    461                 0\n",
       "289             eugene boudin   111    444                 0\n",
       "180             childe hassam   110    437                 0\n",
       "476                ilya repin   108    431                 0\n",
       "504             ivan shishkin   104    416                 0\n",
       "929          raphael kirchner   103    413                 0\n",
       "448             henri matisse    98    393                 0\n",
       "978             salvador dali    96    385                 0\n",
       "157             camille corot    96    381                 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:10722, valid:5281, test:4007\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "N_TOP = 25\n",
    "\n",
    "df = df_classes.groupby([\"subset\",\"artist\"]).size().reset_index()\n",
    "df.columns = [\"subset\", \"artist\", \"size\"]\n",
    "df = df.pivot(index=\"artist\",columns=\"subset\", values=\"size\")\n",
    "df = df.reset_index()\n",
    "df = df.fillna(0).sort_values(by=\"train\", ascending=False)\n",
    "df[\"train\"] = df[\"train\"].astype(np.int16)\n",
    "df[\"test\"] = df[\"test\"].astype(np.int16)\n",
    "df[\"uncertain artist\"] = df[\"uncertain artist\"].astype(np.int16)\n",
    "\n",
    "df=df.sort_values(by=\"train\", ascending=False)\n",
    "\n",
    "top_artists = df[\"artist\"].values[:N_TOP]\n",
    "display(df.head(N_TOP))\n",
    "\n",
    "df_all = df_classes[df_classes[\"artist\"].isin(top_artists)].reset_index(drop = True)\n",
    "le = LabelEncoder()\n",
    "df_all[\"artist_class\"] = le.fit_transform(df_all[\"artist\"].values)\n",
    "class_names = le.classes_\n",
    "\n",
    "    \n",
    "    \n",
    "df_train = df_all.query(\"subset == 'train'\").reset_index(drop = True)\n",
    "df_test = df_all.query(\"subset == 'test'\").reset_index(drop = True)\n",
    "\n",
    "\n",
    "df_train, df_valid, y_train, y_valid =  train_test_split(df_train, df_train[\"artist\"], \n",
    "                                                                   test_size=0.33, random_state=42, \n",
    "                                                                   stratify=df_train[\"artist\"])\n",
    "\n",
    "\n",
    "print(f\"train:{df_train.shape[0]}, valid:{df_valid.shape[0]}, test:{df_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471c43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.reset_index().reset_index().rename({\"index\":\"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56c7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(labels=\"index\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be19de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.rename(columns={\"level_0\":\"index\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91354dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>phash</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>subset</th>\n",
       "      <th>artist_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Naive_Art_Primitivism/pablo-picasso_jug-with-h...</td>\n",
       "      <td>pablo picasso</td>\n",
       "      <td>['Naive Art Primitivism']</td>\n",
       "      <td>jug-with-handle-1954</td>\n",
       "      <td>c8263591cb59b567</td>\n",
       "      <td>1382</td>\n",
       "      <td>2132</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Impressionism/henri-matisse_blue-pot-and-lemon...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Impressionism']</td>\n",
       "      <td>blue-pot-and-lemon-1897</td>\n",
       "      <td>8c8ca5955e6a639b</td>\n",
       "      <td>1668</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Realism/nicholas-roerich_the-kremlin-tower-of-...</td>\n",
       "      <td>nicholas roerich</td>\n",
       "      <td>['Realism']</td>\n",
       "      <td>the-kremlin-tower-of-novgorod-1903</td>\n",
       "      <td>f6d6b6b6b6048425</td>\n",
       "      <td>1382</td>\n",
       "      <td>1539</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Realism/ivan-shishkin_polesye.jpg</td>\n",
       "      <td>ivan shishkin</td>\n",
       "      <td>['Realism']</td>\n",
       "      <td>polesye</td>\n",
       "      <td>83ed70178ee36e18</td>\n",
       "      <td>2314</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Post_Impressionism/vincent-van-gogh_still-life...</td>\n",
       "      <td>vincent van gogh</td>\n",
       "      <td>['Post Impressionism']</td>\n",
       "      <td>still-life-with-apples-1887</td>\n",
       "      <td>87e4b097c4e80fd5</td>\n",
       "      <td>1935</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           filename            artist  \\\n",
       "0      0  Naive_Art_Primitivism/pablo-picasso_jug-with-h...     pablo picasso   \n",
       "1      1  Impressionism/henri-matisse_blue-pot-and-lemon...     henri matisse   \n",
       "2      2  Realism/nicholas-roerich_the-kremlin-tower-of-...  nicholas roerich   \n",
       "3      3                  Realism/ivan-shishkin_polesye.jpg     ivan shishkin   \n",
       "4      4  Post_Impressionism/vincent-van-gogh_still-life...  vincent van gogh   \n",
       "\n",
       "                       genre                         description  \\\n",
       "0  ['Naive Art Primitivism']                jug-with-handle-1954   \n",
       "1          ['Impressionism']             blue-pot-and-lemon-1897   \n",
       "2                ['Realism']  the-kremlin-tower-of-novgorod-1903   \n",
       "3                ['Realism']                             polesye   \n",
       "4     ['Post Impressionism']         still-life-with-apples-1887   \n",
       "\n",
       "              phash  width  height  genre_count subset  artist_class  \n",
       "0  c8263591cb59b567   1382    2132            1  train            17  \n",
       "1  8c8ca5955e6a639b   1668    1382            1  train             9  \n",
       "2  f6d6b6b6b6048425   1382    1539            1  train            16  \n",
       "3  83ed70178ee36e18   2314    1382            1  train            12  \n",
       "4  87e4b097c4e80fd5   1935    1382            1  train            24  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b71a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>phash</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>genre_count</th>\n",
       "      <th>subset</th>\n",
       "      <th>artist_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_blue-nude...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>blue-nude-1952</td>\n",
       "      <td>afbcd133d0ccc069</td>\n",
       "      <td>1382</td>\n",
       "      <td>1769</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_blue-nude...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>blue-nude</td>\n",
       "      <td>ff58d824d109cc6e</td>\n",
       "      <td>1382</td>\n",
       "      <td>2145</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_cut-outs-...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>cut-outs-1</td>\n",
       "      <td>b2cf336117ca8713</td>\n",
       "      <td>2092</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_cut-outs.jpg</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>cut-outs</td>\n",
       "      <td>bff3c8b6c0c9c08c</td>\n",
       "      <td>2082</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abstract_Expressionism/henri-matisse_la-gerbe-...</td>\n",
       "      <td>henri matisse</td>\n",
       "      <td>['Abstract Expressionism']</td>\n",
       "      <td>la-gerbe-1953</td>\n",
       "      <td>acbccdc290b3db05</td>\n",
       "      <td>1675</td>\n",
       "      <td>1382</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename         artist  \\\n",
       "0  Abstract_Expressionism/henri-matisse_blue-nude...  henri matisse   \n",
       "1  Abstract_Expressionism/henri-matisse_blue-nude...  henri matisse   \n",
       "2  Abstract_Expressionism/henri-matisse_cut-outs-...  henri matisse   \n",
       "3  Abstract_Expressionism/henri-matisse_cut-outs.jpg  henri matisse   \n",
       "4  Abstract_Expressionism/henri-matisse_la-gerbe-...  henri matisse   \n",
       "\n",
       "                        genre     description             phash  width  \\\n",
       "0  ['Abstract Expressionism']  blue-nude-1952  afbcd133d0ccc069   1382   \n",
       "1  ['Abstract Expressionism']       blue-nude  ff58d824d109cc6e   1382   \n",
       "2  ['Abstract Expressionism']      cut-outs-1  b2cf336117ca8713   2092   \n",
       "3  ['Abstract Expressionism']        cut-outs  bff3c8b6c0c9c08c   2082   \n",
       "4  ['Abstract Expressionism']   la-gerbe-1953  acbccdc290b3db05   1675   \n",
       "\n",
       "   height  genre_count subset  artist_class  \n",
       "0    1769            1   test             9  \n",
       "1    2145            1   test             9  \n",
       "2    1382            1   test             9  \n",
       "3    1382            1   test             9  \n",
       "4    1382            1   test             9  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57259e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam): # size : [B, C, W, H]\n",
    "    W = size[2] # 이미지의 width\n",
    "    H = size[3] # 이미지의 height\n",
    "    cut_rat = np.sqrt(1. - lam)  # 패치 크기의 비율 정하기\n",
    "    cut_w = np.int32(W * cut_rat)  # 패치의 너비\n",
    "    cut_h = np.int32(H * cut_rat)  # 패치의 높이\n",
    "\n",
    "    # uniform\n",
    "    # 기존 이미지의 크기에서 랜덤하게 값을 가져옵니다.(중간 좌표 추출)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    # 패치 부분에 대한 좌표값을 추출합니다.\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f51a4f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df):\n",
    "    ds_path = \"./archive/\"\n",
    "    filenames = [ f\"{ds_path}/{filename}\" for filename in  df[\"filename\"].values]\n",
    "    labels = [artist for artist in df[\"artist_class\"]]\n",
    "    #ds = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    #return ds\n",
    "    return filenames,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb37ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_paths, train_labels = get_data(df_train)\n",
    "val_img_paths, val_labels = get_data(df_valid)\n",
    "test_img_paths, test_labels = get_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a4799df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Data Imbalance 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0e3995d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_class\n",
       "0      444\n",
       "1      339\n",
       "2      255\n",
       "3      474\n",
       "4      293\n",
       "5      715\n",
       "6      326\n",
       "7      297\n",
       "8      403\n",
       "9      263\n",
       "10     289\n",
       "11     309\n",
       "12     279\n",
       "13     419\n",
       "14     410\n",
       "15     309\n",
       "16     973\n",
       "17     409\n",
       "18     310\n",
       "19     748\n",
       "20     495\n",
       "21     277\n",
       "22     416\n",
       "23     258\n",
       "24    1012\n",
       "Name: artist_class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('artist_class')['artist_class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "179356e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = list(df_train.groupby('artist_class')['artist_class'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04cb0064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[444,\n",
       " 339,\n",
       " 255,\n",
       " 474,\n",
       " 293,\n",
       " 715,\n",
       " 326,\n",
       " 297,\n",
       " 403,\n",
       " 263,\n",
       " 289,\n",
       " 309,\n",
       " 279,\n",
       " 419,\n",
       " 410,\n",
       " 309,\n",
       " 973,\n",
       " 409,\n",
       " 310,\n",
       " 748,\n",
       " 495,\n",
       " 277,\n",
       " 416,\n",
       " 258,\n",
       " 1012]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016702aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "albrecht durer            444\n",
       "boris kustodiev           339\n",
       "camille corot             255\n",
       "camille pissarro          474\n",
       "childe hassam             293\n",
       "claude monet              715\n",
       "edgar degas               326\n",
       "eugene boudin             297\n",
       "gustave dore              403\n",
       "henri matisse             263\n",
       "ilya repin                289\n",
       "ivan aivazovsky           309\n",
       "ivan shishkin             279\n",
       "john singer sargent       419\n",
       "marc chagall              410\n",
       "martiros saryan           309\n",
       "nicholas roerich          973\n",
       "pablo picasso             409\n",
       "paul cezanne              310\n",
       "pierre auguste renoir     748\n",
       "pyotr konchalovsky        495\n",
       "raphael kirchner          277\n",
       "rembrandt                 416\n",
       "salvador dali             258\n",
       "vincent van gogh         1012\n",
       "Name: artist, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(\"artist\")['artist'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15e86729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17,\n",
       " 9,\n",
       " 16,\n",
       " 12,\n",
       " 24,\n",
       " 8,\n",
       " 16,\n",
       " 10,\n",
       " 19,\n",
       " 2,\n",
       " 22,\n",
       " 19,\n",
       " 24,\n",
       " 13,\n",
       " 24,\n",
       " 22,\n",
       " 8,\n",
       " 5,\n",
       " 17,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 14,\n",
       " 19,\n",
       " 0,\n",
       " 16,\n",
       " 23,\n",
       " 13,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 16,\n",
       " 24,\n",
       " 2,\n",
       " 18,\n",
       " 12,\n",
       " 19,\n",
       " 20,\n",
       " 4,\n",
       " 21,\n",
       " 20,\n",
       " 20,\n",
       " 11,\n",
       " 17,\n",
       " 21,\n",
       " 10,\n",
       " 19,\n",
       " 5,\n",
       " 3,\n",
       " 21,\n",
       " 13,\n",
       " 6,\n",
       " 17,\n",
       " 3,\n",
       " 1,\n",
       " 14,\n",
       " 24,\n",
       " 16,\n",
       " 24,\n",
       " 8,\n",
       " 14,\n",
       " 10,\n",
       " 8,\n",
       " 20,\n",
       " 19,\n",
       " 20,\n",
       " 4,\n",
       " 17,\n",
       " 19,\n",
       " 10,\n",
       " 24,\n",
       " 20,\n",
       " 0,\n",
       " 0,\n",
       " 20,\n",
       " 9,\n",
       " 24,\n",
       " 8,\n",
       " 12,\n",
       " 14,\n",
       " 5,\n",
       " 24,\n",
       " 3,\n",
       " 17,\n",
       " 13,\n",
       " 24,\n",
       " 7,\n",
       " 5,\n",
       " 13,\n",
       " 20,\n",
       " 0,\n",
       " 19,\n",
       " 16,\n",
       " 13,\n",
       " 20,\n",
       " 20,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 19,\n",
       " 24,\n",
       " 3,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 8,\n",
       " 12,\n",
       " 19,\n",
       " 9,\n",
       " 20,\n",
       " 0,\n",
       " 17,\n",
       " 22,\n",
       " 2,\n",
       " 5,\n",
       " 10,\n",
       " 8,\n",
       " 22,\n",
       " 9,\n",
       " 19,\n",
       " 10,\n",
       " 19,\n",
       " 19,\n",
       " 3,\n",
       " 16,\n",
       " 10,\n",
       " 1,\n",
       " 10,\n",
       " 23,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 21,\n",
       " 22,\n",
       " 11,\n",
       " 23,\n",
       " 16,\n",
       " 19,\n",
       " 24,\n",
       " 5,\n",
       " 2,\n",
       " 18,\n",
       " 17,\n",
       " 13,\n",
       " 19,\n",
       " 15,\n",
       " 18,\n",
       " 4,\n",
       " 16,\n",
       " 24,\n",
       " 19,\n",
       " 24,\n",
       " 19,\n",
       " 24,\n",
       " 5,\n",
       " 1,\n",
       " 14,\n",
       " 1,\n",
       " 14,\n",
       " 20,\n",
       " 2,\n",
       " 21,\n",
       " 12,\n",
       " 21,\n",
       " 23,\n",
       " 22,\n",
       " 19,\n",
       " 16,\n",
       " 20,\n",
       " 24,\n",
       " 24,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 18,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 11,\n",
       " 13,\n",
       " 24,\n",
       " 0,\n",
       " 6,\n",
       " 11,\n",
       " 9,\n",
       " 6,\n",
       " 24,\n",
       " 4,\n",
       " 0,\n",
       " 24,\n",
       " 12,\n",
       " 6,\n",
       " 21,\n",
       " 2,\n",
       " 19,\n",
       " 22,\n",
       " 24,\n",
       " 7,\n",
       " 10,\n",
       " 24,\n",
       " 3,\n",
       " 24,\n",
       " 18,\n",
       " 5,\n",
       " 16,\n",
       " 14,\n",
       " 19,\n",
       " 11,\n",
       " 20,\n",
       " 5,\n",
       " 19,\n",
       " 16,\n",
       " 19,\n",
       " 12,\n",
       " 23,\n",
       " 22,\n",
       " 19,\n",
       " 3,\n",
       " 16,\n",
       " 14,\n",
       " 17,\n",
       " 21,\n",
       " 18,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 16,\n",
       " 24,\n",
       " 12,\n",
       " 16,\n",
       " 16,\n",
       " 14,\n",
       " 13,\n",
       " 0,\n",
       " 24,\n",
       " 12,\n",
       " 0,\n",
       " 5,\n",
       " 13,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 16,\n",
       " 24,\n",
       " 3,\n",
       " 21,\n",
       " 13,\n",
       " 14,\n",
       " 12,\n",
       " 20,\n",
       " 22,\n",
       " 14,\n",
       " 0,\n",
       " 11,\n",
       " 19,\n",
       " 24,\n",
       " 14,\n",
       " 10,\n",
       " 21,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 18,\n",
       " 16,\n",
       " 1,\n",
       " 24,\n",
       " 0,\n",
       " 9,\n",
       " 19,\n",
       " 19,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 24,\n",
       " 10,\n",
       " 4,\n",
       " 18,\n",
       " 16,\n",
       " 8,\n",
       " 22,\n",
       " 15,\n",
       " 3,\n",
       " 18,\n",
       " 14,\n",
       " 24,\n",
       " 5,\n",
       " 14,\n",
       " 23,\n",
       " 19,\n",
       " 23,\n",
       " 24,\n",
       " 2,\n",
       " 5,\n",
       " 24,\n",
       " 22,\n",
       " 0,\n",
       " 16,\n",
       " 20,\n",
       " 3,\n",
       " 17,\n",
       " 23,\n",
       " 17,\n",
       " 19,\n",
       " 16,\n",
       " 10,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 18,\n",
       " 6,\n",
       " 17,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 24,\n",
       " 16,\n",
       " 20,\n",
       " 4,\n",
       " 20,\n",
       " 15,\n",
       " 11,\n",
       " 24,\n",
       " 19,\n",
       " 6,\n",
       " 16,\n",
       " 7,\n",
       " 24,\n",
       " 19,\n",
       " 16,\n",
       " 4,\n",
       " 24,\n",
       " 20,\n",
       " 10,\n",
       " 24,\n",
       " 21,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 17,\n",
       " 24,\n",
       " 24,\n",
       " 10,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 20,\n",
       " 13,\n",
       " 11,\n",
       " 16,\n",
       " 18,\n",
       " 14,\n",
       " 8,\n",
       " 23,\n",
       " 24,\n",
       " 5,\n",
       " 13,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 24,\n",
       " 17,\n",
       " 13,\n",
       " 22,\n",
       " 16,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 17,\n",
       " 16,\n",
       " 24,\n",
       " 13,\n",
       " 21,\n",
       " 4,\n",
       " 5,\n",
       " 21,\n",
       " 20,\n",
       " 3,\n",
       " 1,\n",
       " 16,\n",
       " 24,\n",
       " 20,\n",
       " 24,\n",
       " 22,\n",
       " 18,\n",
       " 24,\n",
       " 23,\n",
       " 16,\n",
       " 23,\n",
       " 3,\n",
       " 18,\n",
       " 22,\n",
       " 14,\n",
       " 12,\n",
       " 20,\n",
       " 6,\n",
       " 16,\n",
       " 13,\n",
       " 21,\n",
       " 9,\n",
       " 24,\n",
       " 3,\n",
       " 1,\n",
       " 18,\n",
       " 10,\n",
       " 15,\n",
       " 3,\n",
       " 13,\n",
       " 18,\n",
       " 16,\n",
       " 17,\n",
       " 20,\n",
       " 16,\n",
       " 24,\n",
       " 13,\n",
       " 7,\n",
       " 20,\n",
       " 6,\n",
       " 22,\n",
       " 19,\n",
       " 20,\n",
       " 19,\n",
       " 22,\n",
       " 12,\n",
       " 5,\n",
       " 21,\n",
       " 16,\n",
       " 24,\n",
       " 20,\n",
       " 24,\n",
       " 16,\n",
       " 17,\n",
       " 24,\n",
       " 18,\n",
       " 5,\n",
       " 19,\n",
       " 14,\n",
       " 20,\n",
       " 23,\n",
       " 13,\n",
       " 11,\n",
       " 1,\n",
       " 15,\n",
       " 13,\n",
       " 24,\n",
       " 13,\n",
       " 9,\n",
       " 4,\n",
       " 19,\n",
       " 11,\n",
       " 24,\n",
       " 11,\n",
       " 8,\n",
       " 2,\n",
       " 24,\n",
       " 7,\n",
       " 18,\n",
       " 4,\n",
       " 16,\n",
       " 13,\n",
       " 23,\n",
       " 5,\n",
       " 15,\n",
       " 11,\n",
       " 16,\n",
       " 23,\n",
       " 11,\n",
       " 21,\n",
       " 16,\n",
       " 20,\n",
       " 2,\n",
       " 19,\n",
       " 23,\n",
       " 19,\n",
       " 1,\n",
       " 10,\n",
       " 16,\n",
       " 5,\n",
       " 9,\n",
       " 12,\n",
       " 18,\n",
       " 8,\n",
       " 16,\n",
       " 18,\n",
       " 17,\n",
       " 20,\n",
       " 20,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 20,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 23,\n",
       " 22,\n",
       " 2,\n",
       " 16,\n",
       " 5,\n",
       " 18,\n",
       " 15,\n",
       " 19,\n",
       " 14,\n",
       " 13,\n",
       " 0,\n",
       " 8,\n",
       " 17,\n",
       " 23,\n",
       " 20,\n",
       " 1,\n",
       " 20,\n",
       " 21,\n",
       " 24,\n",
       " 18,\n",
       " 0,\n",
       " 16,\n",
       " 12,\n",
       " 11,\n",
       " 3,\n",
       " 15,\n",
       " 16,\n",
       " 19,\n",
       " 5,\n",
       " 2,\n",
       " 11,\n",
       " 24,\n",
       " 24,\n",
       " 6,\n",
       " 16,\n",
       " 13,\n",
       " 22,\n",
       " 24,\n",
       " 5,\n",
       " 15,\n",
       " 19,\n",
       " 22,\n",
       " 6,\n",
       " 2,\n",
       " 11,\n",
       " 16,\n",
       " 3,\n",
       " 15,\n",
       " 4,\n",
       " 20,\n",
       " 3,\n",
       " 23,\n",
       " 6,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 9,\n",
       " 12,\n",
       " 19,\n",
       " 13,\n",
       " 19,\n",
       " 21,\n",
       " 24,\n",
       " 24,\n",
       " 23,\n",
       " 15,\n",
       " 5,\n",
       " 16,\n",
       " 6,\n",
       " 5,\n",
       " 16,\n",
       " 1,\n",
       " 19,\n",
       " 6,\n",
       " 3,\n",
       " 23,\n",
       " 24,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 15,\n",
       " 3,\n",
       " 22,\n",
       " 4,\n",
       " 22,\n",
       " 22,\n",
       " 0,\n",
       " 7,\n",
       " 22,\n",
       " 10,\n",
       " 19,\n",
       " 5,\n",
       " 16,\n",
       " 24,\n",
       " 17,\n",
       " 22,\n",
       " 19,\n",
       " 3,\n",
       " 22,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 24,\n",
       " 22,\n",
       " 24,\n",
       " 17,\n",
       " 1,\n",
       " 17,\n",
       " 16,\n",
       " 19,\n",
       " 3,\n",
       " 16,\n",
       " 19,\n",
       " 24,\n",
       " 5,\n",
       " 10,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 23,\n",
       " 5,\n",
       " 14,\n",
       " 14,\n",
       " 10,\n",
       " 23,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 18,\n",
       " 16,\n",
       " 24,\n",
       " 23,\n",
       " 23,\n",
       " 22,\n",
       " 13,\n",
       " 20,\n",
       " 17,\n",
       " 12,\n",
       " 11,\n",
       " 15,\n",
       " 20,\n",
       " 0,\n",
       " 16,\n",
       " 14,\n",
       " 1,\n",
       " 24,\n",
       " 6,\n",
       " 16,\n",
       " 9,\n",
       " 16,\n",
       " 18,\n",
       " 8,\n",
       " 22,\n",
       " 24,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 16,\n",
       " 24,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 24,\n",
       " 19,\n",
       " 5,\n",
       " 24,\n",
       " 18,\n",
       " 20,\n",
       " 3,\n",
       " 10,\n",
       " 17,\n",
       " 24,\n",
       " 14,\n",
       " 4,\n",
       " 4,\n",
       " 18,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 24,\n",
       " 16,\n",
       " 22,\n",
       " 4,\n",
       " 20,\n",
       " 17,\n",
       " 18,\n",
       " 22,\n",
       " 5,\n",
       " 3,\n",
       " 11,\n",
       " 14,\n",
       " 13,\n",
       " 12,\n",
       " 5,\n",
       " 19,\n",
       " 7,\n",
       " 7,\n",
       " 20,\n",
       " 20,\n",
       " 22,\n",
       " 24,\n",
       " 14,\n",
       " 23,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 17,\n",
       " 20,\n",
       " 12,\n",
       " 24,\n",
       " 16,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 13,\n",
       " 9,\n",
       " 13,\n",
       " 20,\n",
       " 16,\n",
       " 1,\n",
       " 19,\n",
       " 5,\n",
       " 21,\n",
       " 17,\n",
       " 5,\n",
       " 11,\n",
       " 19,\n",
       " 23,\n",
       " 19,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 16,\n",
       " 5,\n",
       " 8,\n",
       " 17,\n",
       " 3,\n",
       " 4,\n",
       " 24,\n",
       " 16,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 24,\n",
       " 19,\n",
       " 20,\n",
       " 6,\n",
       " 5,\n",
       " 18,\n",
       " 16,\n",
       " 19,\n",
       " 0,\n",
       " 0,\n",
       " 14,\n",
       " 11,\n",
       " 6,\n",
       " 20,\n",
       " 11,\n",
       " 24,\n",
       " 1,\n",
       " 16,\n",
       " 5,\n",
       " 19,\n",
       " 5,\n",
       " 17,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 12,\n",
       " 5,\n",
       " 13,\n",
       " 6,\n",
       " 20,\n",
       " 20,\n",
       " 6,\n",
       " 20,\n",
       " 16,\n",
       " 17,\n",
       " 3,\n",
       " 16,\n",
       " 5,\n",
       " 8,\n",
       " 17,\n",
       " 14,\n",
       " 5,\n",
       " 14,\n",
       " 16,\n",
       " 2,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 16,\n",
       " 16,\n",
       " 24,\n",
       " 5,\n",
       " 16,\n",
       " 10,\n",
       " 24,\n",
       " 0,\n",
       " 21,\n",
       " 16,\n",
       " 15,\n",
       " 12,\n",
       " 21,\n",
       " 22,\n",
       " 16,\n",
       " 1,\n",
       " 23,\n",
       " 18,\n",
       " 11,\n",
       " 24,\n",
       " 20,\n",
       " 3,\n",
       " 24,\n",
       " 11,\n",
       " 12,\n",
       " 9,\n",
       " 15,\n",
       " 3,\n",
       " 15,\n",
       " 7,\n",
       " 18,\n",
       " 22,\n",
       " 15,\n",
       " 18,\n",
       " 19,\n",
       " 3,\n",
       " 17,\n",
       " 6,\n",
       " 12,\n",
       " 19,\n",
       " 15,\n",
       " 20,\n",
       " 11,\n",
       " 9,\n",
       " 13,\n",
       " 13,\n",
       " 5,\n",
       " 5,\n",
       " 11,\n",
       " 8,\n",
       " 3,\n",
       " 20,\n",
       " 14,\n",
       " 9,\n",
       " 16,\n",
       " 21,\n",
       " 5,\n",
       " 19,\n",
       " 6,\n",
       " 3,\n",
       " 16,\n",
       " 24,\n",
       " 9,\n",
       " 13,\n",
       " 13,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 24,\n",
       " 1,\n",
       " 3,\n",
       " 20,\n",
       " 12,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 22,\n",
       " 16,\n",
       " 12,\n",
       " 6,\n",
       " 24,\n",
       " 13,\n",
       " 12,\n",
       " 4,\n",
       " 14,\n",
       " 6,\n",
       " 24,\n",
       " 23,\n",
       " 14,\n",
       " 14,\n",
       " 17,\n",
       " 24,\n",
       " 20,\n",
       " 2,\n",
       " 24,\n",
       " 5,\n",
       " 24,\n",
       " 14,\n",
       " 16,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 17,\n",
       " 22,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 20,\n",
       " 16,\n",
       " 19,\n",
       " 3,\n",
       " 10,\n",
       " 19,\n",
       " 5,\n",
       " 8,\n",
       " 19,\n",
       " 21,\n",
       " 16,\n",
       " 10,\n",
       " 11,\n",
       " 5,\n",
       " 13,\n",
       " 21,\n",
       " 11,\n",
       " 8,\n",
       " 17,\n",
       " 20,\n",
       " 19,\n",
       " 2,\n",
       " 20,\n",
       " 19,\n",
       " 18,\n",
       " 15,\n",
       " 9,\n",
       " 21,\n",
       " 24,\n",
       " 16,\n",
       " 10,\n",
       " 17,\n",
       " 7,\n",
       " 19,\n",
       " 14,\n",
       " 16,\n",
       " 11,\n",
       " 24,\n",
       " 24,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 16,\n",
       " 21,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 24,\n",
       " 14,\n",
       " 7,\n",
       " 22,\n",
       " 6,\n",
       " 18,\n",
       " 11,\n",
       " 20,\n",
       " 20,\n",
       " 3,\n",
       " 24,\n",
       " 14,\n",
       " 17,\n",
       " 13,\n",
       " 2,\n",
       " 0,\n",
       " 15,\n",
       " 12,\n",
       " 12,\n",
       " 14,\n",
       " 14,\n",
       " 19,\n",
       " 7,\n",
       " 5,\n",
       " 10,\n",
       " 22,\n",
       " 22,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 24,\n",
       " 3,\n",
       " 23,\n",
       " 17,\n",
       " 24,\n",
       " 8,\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "858812b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights(labels, nclasses):\n",
    "    labels = np.array(labels) \n",
    "    weight_arr = np.zeros_like(labels) \n",
    "    \n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    for cls in range(nclasses):\n",
    "        weight_arr = np.where(labels == cls, 1/counts[cls], weight_arr)\n",
    "        # 각 클래스의의 인덱스를 산출하여 해당 클래스 개수의 역수를 확률로 할당한다.\n",
    "        # 이를 통해 각 클래스의 전체 가중치를 동일하게 한다.\n",
    " \n",
    "    return weight_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74eabd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0024, 0.0038, 0.0010,  ..., 0.0010, 0.0031, 0.0036], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "w = make_weights(train_labels,25)\n",
    "w= torch.FloatTensor(w).to(\"cuda:0\")\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46a32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = np.array(image)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc313479",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'BATCH_SIZE':16,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "764bcc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2),\n",
    "                            A.RandomCrop(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.HorizontalFlip(p=0.5),\n",
    "                            A.VerticalFlip(p=0.5),\n",
    "                            A.ShiftScaleRotate(p=0.5),\n",
    "                            A.OneOf([\n",
    "                                A.CLAHE(clip_limit=2),\n",
    "                                A.RandomBrightnessContrast(),\n",
    "                            ], p=0.3),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, \n",
    "                                        always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2),\n",
    "                            A.RandomCrop(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, \n",
    "                                        always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, \n",
    "                                        always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ce6c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_img_paths, train_labels, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n",
    "\n",
    "val_dataset = CustomDataset(val_img_paths, val_labels, val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc60df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=False).to(\"cuda:0\")\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 1024),\n",
    "    nn.Linear(1024, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ef264da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.conv1.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bd7e132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=25, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e5cbeda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\jiseon\\anaconda3\\envs\\test\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "842d07f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JiSeon\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1024]       2,098,176\n",
      "          Linear-175                   [-1, 25]          25,625\n",
      "================================================================\n",
      "Total params: 25,631,833\n",
      "Trainable params: 25,631,833\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.78\n",
      "Estimated Total Size (MB): 384.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary as summary\n",
    "\n",
    "summary(resnet.to(\"cuda:0\"), (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a364f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([64, 3, 7, 7])\n",
      "bn1.weight torch.Size([64])\n",
      "bn1.bias torch.Size([64])\n",
      "layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "layer1.0.bn1.weight torch.Size([64])\n",
      "layer1.0.bn1.bias torch.Size([64])\n",
      "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight torch.Size([64])\n",
      "layer1.0.bn2.bias torch.Size([64])\n",
      "layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.bn3.weight torch.Size([256])\n",
      "layer1.0.bn3.bias torch.Size([256])\n",
      "layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.downsample.1.weight torch.Size([256])\n",
      "layer1.0.downsample.1.bias torch.Size([256])\n",
      "layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.1.bn1.weight torch.Size([64])\n",
      "layer1.1.bn1.bias torch.Size([64])\n",
      "layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight torch.Size([64])\n",
      "layer1.1.bn2.bias torch.Size([64])\n",
      "layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.1.bn3.weight torch.Size([256])\n",
      "layer1.1.bn3.bias torch.Size([256])\n",
      "layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.2.bn1.weight torch.Size([64])\n",
      "layer1.2.bn1.bias torch.Size([64])\n",
      "layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.2.bn2.weight torch.Size([64])\n",
      "layer1.2.bn2.bias torch.Size([64])\n",
      "layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.2.bn3.weight torch.Size([256])\n",
      "layer1.2.bn3.bias torch.Size([256])\n",
      "layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "layer2.0.bn1.weight torch.Size([128])\n",
      "layer2.0.bn1.bias torch.Size([128])\n",
      "layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight torch.Size([128])\n",
      "layer2.0.bn2.bias torch.Size([128])\n",
      "layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.0.bn3.weight torch.Size([512])\n",
      "layer2.0.bn3.bias torch.Size([512])\n",
      "layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "layer2.0.downsample.1.weight torch.Size([512])\n",
      "layer2.0.downsample.1.bias torch.Size([512])\n",
      "layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.1.bn1.weight torch.Size([128])\n",
      "layer2.1.bn1.bias torch.Size([128])\n",
      "layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight torch.Size([128])\n",
      "layer2.1.bn2.bias torch.Size([128])\n",
      "layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.1.bn3.weight torch.Size([512])\n",
      "layer2.1.bn3.bias torch.Size([512])\n",
      "layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.2.bn1.weight torch.Size([128])\n",
      "layer2.2.bn1.bias torch.Size([128])\n",
      "layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.2.bn2.weight torch.Size([128])\n",
      "layer2.2.bn2.bias torch.Size([128])\n",
      "layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.2.bn3.weight torch.Size([512])\n",
      "layer2.2.bn3.bias torch.Size([512])\n",
      "layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.3.bn1.weight torch.Size([128])\n",
      "layer2.3.bn1.bias torch.Size([128])\n",
      "layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.3.bn2.weight torch.Size([128])\n",
      "layer2.3.bn2.bias torch.Size([128])\n",
      "layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.3.bn3.weight torch.Size([512])\n",
      "layer2.3.bn3.bias torch.Size([512])\n",
      "layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "layer3.0.bn1.weight torch.Size([256])\n",
      "layer3.0.bn1.bias torch.Size([256])\n",
      "layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight torch.Size([256])\n",
      "layer3.0.bn2.bias torch.Size([256])\n",
      "layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.0.bn3.weight torch.Size([1024])\n",
      "layer3.0.bn3.bias torch.Size([1024])\n",
      "layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "layer3.0.downsample.1.weight torch.Size([1024])\n",
      "layer3.0.downsample.1.bias torch.Size([1024])\n",
      "layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.1.bn1.weight torch.Size([256])\n",
      "layer3.1.bn1.bias torch.Size([256])\n",
      "layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight torch.Size([256])\n",
      "layer3.1.bn2.bias torch.Size([256])\n",
      "layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.1.bn3.weight torch.Size([1024])\n",
      "layer3.1.bn3.bias torch.Size([1024])\n",
      "layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.2.bn1.weight torch.Size([256])\n",
      "layer3.2.bn1.bias torch.Size([256])\n",
      "layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.2.bn2.weight torch.Size([256])\n",
      "layer3.2.bn2.bias torch.Size([256])\n",
      "layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.2.bn3.weight torch.Size([1024])\n",
      "layer3.2.bn3.bias torch.Size([1024])\n",
      "layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.3.bn1.weight torch.Size([256])\n",
      "layer3.3.bn1.bias torch.Size([256])\n",
      "layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.3.bn2.weight torch.Size([256])\n",
      "layer3.3.bn2.bias torch.Size([256])\n",
      "layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.3.bn3.weight torch.Size([1024])\n",
      "layer3.3.bn3.bias torch.Size([1024])\n",
      "layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.4.bn1.weight torch.Size([256])\n",
      "layer3.4.bn1.bias torch.Size([256])\n",
      "layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.4.bn2.weight torch.Size([256])\n",
      "layer3.4.bn2.bias torch.Size([256])\n",
      "layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.4.bn3.weight torch.Size([1024])\n",
      "layer3.4.bn3.bias torch.Size([1024])\n",
      "layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.5.bn1.weight torch.Size([256])\n",
      "layer3.5.bn1.bias torch.Size([256])\n",
      "layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.5.bn2.weight torch.Size([256])\n",
      "layer3.5.bn2.bias torch.Size([256])\n",
      "layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.5.bn3.weight torch.Size([1024])\n",
      "layer3.5.bn3.bias torch.Size([1024])\n",
      "layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "layer4.0.bn1.weight torch.Size([512])\n",
      "layer4.0.bn1.bias torch.Size([512])\n",
      "layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight torch.Size([512])\n",
      "layer4.0.bn2.bias torch.Size([512])\n",
      "layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.0.bn3.weight torch.Size([2048])\n",
      "layer4.0.bn3.bias torch.Size([2048])\n",
      "layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "layer4.0.downsample.1.weight torch.Size([2048])\n",
      "layer4.0.downsample.1.bias torch.Size([2048])\n",
      "layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.1.bn1.weight torch.Size([512])\n",
      "layer4.1.bn1.bias torch.Size([512])\n",
      "layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight torch.Size([512])\n",
      "layer4.1.bn2.bias torch.Size([512])\n",
      "layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.1.bn3.weight torch.Size([2048])\n",
      "layer4.1.bn3.bias torch.Size([2048])\n",
      "layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.2.bn1.weight torch.Size([512])\n",
      "layer4.2.bn1.bias torch.Size([512])\n",
      "layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.2.bn2.weight torch.Size([512])\n",
      "layer4.2.bn2.bias torch.Size([512])\n",
      "layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.bn3.weight torch.Size([2048])\n",
      "layer4.2.bn3.bias torch.Size([2048])\n",
      "fc.0.weight torch.Size([1024, 2048])\n",
      "fc.0.bias torch.Size([1024])\n",
      "fc.1.weight torch.Size([25, 1024])\n",
      "fc.1.bias torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "for name, param in resnet.named_parameters():\n",
    "    print(name,param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11610912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict_path = './checkpoint/best_model8_weight.pt'\n",
    "weights=torch.load(state_dict_path,map_location=torch.device('cpu'))\n",
    "resnet.load_state_dict(weights['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11b6de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ins = class_count    # 실제 클래스 수 \n",
    " \n",
    "weights = [1 - (x/sum(num_ins)) for x in num_ins]\n",
    "class_weights = torch.FloatTensor(weights).to(\"cuda:0\")\n",
    " \n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54571f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Imbalance 문제 해결 위해 CrossEntropyLoss에 Weight 적용\n",
    "# criterion = nn.CrossEntropyLoss(weight=w)\n",
    "# 모든 매개변수들이 최적화되었는지 관찰\n",
    "optimizer_ft = optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93734263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, saved_dir):\n",
    "    os.makedirs(saved_dir, exist_ok=True)\n",
    "    check_point = {\n",
    "        'net2' : model.state_dict()\n",
    "    }\n",
    "    torch.save(check_point, saved_dir+'/best_model_weight_conv_no_freeze2_fc2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23be2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "def eval_model(model_ft, data_loader, device):\n",
    "  model_ft.eval()\n",
    "\n",
    "  best_acc = 0.0\n",
    "    \n",
    "  ys = []\n",
    "  ypreds = []\n",
    "  for x, y in data_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      _, y_pred = model_ft(x).max(1)\n",
    "    ys.append(y)\n",
    "    ypreds.append(y_pred)\n",
    "\n",
    "  ys = torch.cat(ys)\n",
    "  ypreds = torch.cat(ypreds)\n",
    "\n",
    "  acc = ((ys == ypreds).float().sum() / len(ys)) * 100\n",
    "\n",
    "  if best_acc < acc:\n",
    "        save_model(model_ft, './checkpoint')\n",
    "        print('Succeed save the model')\n",
    "        best_acc=acc\n",
    "        \n",
    "  \n",
    "  return acc.item()\n",
    "\n",
    "\n",
    "def train_model(model_ft,train_loader, val_loader, only_fc,\n",
    "                optimizer_cls,\n",
    "                loss_fn,\n",
    "                n_iter=10, device='cpu'):\n",
    "  train_losses = []\n",
    "  train_acc = []\n",
    "  val_acc = []\n",
    "\n",
    "  if only_fc:\n",
    "    optimizer = optimizer_cls\n",
    "  \n",
    "  else:\n",
    "    optimizer = optimizer_cls(model_ft.parameters())\n",
    "\n",
    "  for epoch in range(n_iter):\n",
    "    running_loss = 0.0\n",
    "    model_ft.train()\n",
    "    n = 0\n",
    "    n_acc = 0\n",
    "\n",
    "    for i, (xx, yy) in tqdm(enumerate(train_loader), total= len(train_loader)):\n",
    "      yy = torch.from_numpy(np.asarray(yy))\n",
    "      xx = xx.to(device)\n",
    "      yy = yy.to(device)\n",
    "      optimizer.zero_grad()\n",
    "        # cutmix\n",
    "      if np.random.random()>0.5:\n",
    "        X, y = xx,yy\n",
    "        lam = np.random.beta(1.0, 1.0)\n",
    "        rand_index = torch.randperm(X.size()[0]).to(device)\n",
    "        target_a = y\n",
    "        target_b = y[rand_index]            \n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(X.size(), lam)\n",
    "        X[:, :, bbx1:bbx2, bby1:bby2] = X[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (X.size()[-1] * X.size()[-2]))\n",
    "        h = model_ft(X)\n",
    "        loss = loss_fn(h, target_a) * lam + loss_fn(h, target_b) * (1. - lam)\n",
    "      else:\n",
    "        h = model_ft(xx)\n",
    "        loss = loss_fn(h,yy)\n",
    "        \n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "      n += len(xx)\n",
    "      _,y_pred = h.max(1)\n",
    "      n_acc += (yy == y_pred).float().sum().item()\n",
    "    \n",
    "    if epoch%1 == 0:\n",
    "        print(\"lr: \", optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    train_losses.append(running_loss/i)\n",
    "    \n",
    "    train_acc.append(n_acc / n)\n",
    "\n",
    "    val_acc.append(eval_model(model_ft, val_loader, device))\n",
    "\n",
    "    print(epoch, train_losses[-1], train_acc[-1], val_acc[-1], flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41740817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9aff5ee2e844aec8663bae8aa412740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "0 1.7602308566260232 0.5291977611940298 68.39015197753906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da72b690c4c4dcda24d80d1d5551d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "1 1.6879994958327311 0.5486007462686567 69.39393615722656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f075489c01844162b56462b099a2871d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "2 1.609650563142403 0.5762126865671642 71.07954406738281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf558855be3742c199d75381358f317e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "3 1.6039006718071052 0.5761194029850746 71.68560791015625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96df3fec7e484cb38551bf488ef3f4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "4 1.5417869285706804 0.5890858208955224 72.68939208984375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac10a2d555ed4b3f8fd02ef678f35280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "5 1.4660928044885797 0.6083955223880597 74.1287841796875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687c1c5ba2a142e8bdb5915f0cad2bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "6 1.4827865726566458 0.6053171641791045 74.45075225830078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4eabdea9df41e494cd14cb5c866aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "7 1.4689578094111786 0.6183768656716417 74.90530395507812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783ad3ffad49499a91c1f47cffe89b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "8 1.458533985643287 0.6162313432835821 75.45454406738281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac32c90d0ec44baa8900e2bedc42d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "9 1.3971750288533522 0.6268656716417911 75.96590423583984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f36c0ee877f481d90fbb7b0d3f4bf65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "10 1.429338390205295 0.6271455223880597 76.1552963256836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96af776bbf244712b7d8438821450a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "11 1.3807424661468142 0.6491604477611941 76.32575988769531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae9bd2a0ddd4722a9d58f70a960a121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "12 1.381399005339641 0.6395522388059701 77.21590423583984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f2b104d51c4aca8e3d7de80c852d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "13 1.3379527890361478 0.65625 77.12120819091797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d0ea97b8244b468d266818e5a552c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "14 1.344296991602366 0.6504664179104478 77.12120819091797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4db6bb225704fa0b3b3af7618f276ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "15 1.3529338100298638 0.6487873134328358 77.44317626953125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f335093784b44e23b3dd1317a08965d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "16 1.2897099698427368 0.6625932835820896 77.99242401123047\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c51c58e761480e91459f9ec228a3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "17 1.281444841592123 0.6712686567164179 78.63636016845703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0659041589c34f78b3db9f332e8596e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "18 1.3282611803979973 0.6644589552238805 77.9734878540039\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb3f4d9426545888959c6410abf99a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "19 1.288315993119783 0.6690298507462686 78.18181610107422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0caa2c4851e247cdb4859b0443a94979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "20 1.225628185120755 0.6751865671641791 79.39393615722656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1768672ac24948984894e6f353de36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "21 1.2830231931667513 0.6694962686567164 78.80681610107422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817beeb546d94e12964a464a9bfd2f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "22 1.252708257714729 0.6769589552238806 79.29924011230469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c348a4feafa4d928431ce0d365351cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "23 1.2115213134408176 0.6765858208955224 79.58332824707031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffad4d6c458441bb28ae796ced5f7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "24 1.2136358372610958 0.6923507462686567 79.79166412353516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e4b35ffc164a69b0ac5695b63b753f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "25 1.1890671317352843 0.7058768656716418 79.90530395507812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c623e0fbdf9449fb60a254bb7848c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "26 1.2005935196830197 0.6819029850746269 80.09469604492188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44a9325109b45b2b8c72e32ed7df034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "27 1.2044418627348894 0.6890858208955224 80.07575225830078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9582f9cfd30742b582bad10a1f80467d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "28 1.1694349613157624 0.7059701492537314 80.41666412353516\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7edb404946641c3bc8b86d9ab5d9b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001\n",
      "Succeed save the model\n",
      "29 1.1756770080693277 0.7010261194029851 80.17045593261719\n"
     ]
    }
   ],
   "source": [
    "resnet.to(\"cuda:0\")\n",
    "\n",
    "train_model(resnet, train_loader, val_loader, only_fc = True, optimizer_cls=optimizer_ft,\n",
    "            loss_fn = criterion, n_iter=30, device='cuda:0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
